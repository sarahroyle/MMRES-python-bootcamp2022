{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp2021/blob/master/04_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2 - Pandas (First part) TODO\n",
    "> An introduction on Pandas basics. TODO Here you will hear (just a bit) about Python *packages* and *modules*. Then you will be introduced to *lists* and *dictionaries*, some of the most versatile data types in Python. Finally, you will become familiar with the concept of *flow control* and the definition of your own *functions*. TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline TODO\n",
    " * [Importing packages](#Importing-packages)\n",
    " * [Lists](#Lists)\n",
    " * [Strings as sequential data types](#Strings-as-sequential-data-types)\n",
    " * [Dictionaries](#Dictionaries)\n",
    " * [Flow control](#Flow-control)\n",
    "   * [The `for` loop](#The-for-loop)\n",
    "   * [The `if`, `elif` and `else` clauses](#The-if,-elif-and-else-clauses)\n",
    " * [User defined functions](#User-defined-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b> Practice cells announce exercises that you should try during the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Extension:</b> Extension cells correspond to exercises (or links to contents) that are a bit more advanced. We recommend to try them after the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> Tip cells just give some advice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b> Caveat cells warn you about the most common pitfalls one founds when starts his/her path learning Python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This document is devised as a tool to enable your self-learning process. If you get stuck at some step or need any kind of help, please don't hesitate to raise your hand and ask for the teacher's guidance.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jd6Y3hlZwe_y",
    "tags": []
   },
   "source": [
    "## What is Pandas?\n",
    "\n",
    "When dealing with numeric matrices and vectors in Python, [NumPy](https://numpy.org/) makes life a lot easier. However, those used to work with dedicated languages like [R](https://www.r-project.org/), doing data analysis directly with NumPy feels like a step back. Fortunately, some nice folks have written the Python Data Analysis Library (a.k.a. [Pandas](http://pandas.pydata.org/)). Pandas provides an R-like DataFrame, produces high quality plots with [matplotlib](https://matplotlib.org/), and integrates nicely with other libraries that expect NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series and DataFrames\n",
    "\n",
    "Pandas works with `Series` of data, that then are arranged in `DataFrame` objects. A dataframe is the object closest to an Excel spreadsheet that we will see throughout the boot camp. Dataframes, though, given that they are integrated in Python and can be combined with so many different packages, are much more powerful than simple Excel spreadsheets. We use to load Pandas with the `pd` alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package with its corresponding alias\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data as a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load data with Pandas we use functions like [`pd.read_excel()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) and [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). As you may have guessed, we choose depending on the format of our input data. For example, `pd.read_excel()` works with `xlsx`, `xls`... `pd.read_csv()` with `csv`, `tsv`, `txt`...\n",
    "\n",
    "These functions have multiple arguments providing great flexibility when importing data, like skipping some rows/columns, specifying the column delimiter or picking a particular sheet within a spreadsheet. Let's begin by importing [`ToySpreadsheet.xlsx`](MMRES-python-bootcamp2022/datasets/ToySpreadsheet.xlsx) from `/MMRES-python-bootcamp2022/datasets` sub-folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading an Excel SpreadSheet and storing it in as a DataFrame called `df`\n",
    "df = pd.read_excel(io='datasets/ToySpreadsheet.xlsx')\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data type of `df`\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataframe basic inspection\n",
    "\n",
    "Usually, the first thing one should do with a new DataFrame is getting familiar with the its data. Pandas DataFrame objects have many *methods* to this aim, like [`.head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html), [`.tail()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html), [`.describe()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame tail\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame (basic) statistical description for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`.info()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) method is particularly useful. It gives the names *columns*, the data type stored in each column and the memory devoted to store the DataFrame. It also shows the number of non-null values by column, from which we can easily estimate the number of *missing values* (`NaN`) by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame general information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these methods, Pandas DataFrame objects very useful have *attributes* like [`.shape`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html), [`.columns`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html) and \n",
    "[`.index`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame shape. Remember: (Rows, Columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame rows\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b>\n",
    "\n",
    "Like *methods*, *attributes* are invoked with the dot `.` symbol. In general, *methods* are invoked with a parenthesis (like `.info()`) and *attributes* without them (like `.shape`). Intuitively, you can consider the *attributes* of a Python object as <ins>things it has</ins>, and *methods* as <ins>things it does</ins>. For example, we could imagine a Python object called `cat` with some attributes and methods.\n",
    "+ Atributes: `cat.age`, `cat.weight`, `cat.gender`, `cat.personality`, `cat.eye_color`, `cat.coat_pattern`, ...\n",
    "+ Methods: `cat.purr()`, `cat.meow()`, `cat.chirp()`, `cat.eat()`, `cat.sleep()`, `cat.scratch()`, ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame visual inspection\n",
    "\n",
    "After a basic DataFrame inspection, we can start with a visual exploration. To this aim we can levergae the Pandas DataFrame method [`.plot`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html) and its related \"submethods\" [`.line()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.line.html), [`.bar()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html), [`.barh()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.barh.html), [`.hist()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.hist.html), [`.box()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.box.html), [`.density()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.density.html), [`.area()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.area.html), [`.pie()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.pie.html), [`.scatter()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html), [`.hexbin()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.hexbin.html), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame line plot\n",
    "df.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b>\n",
    "\n",
    "1) In the 1st code cell below, get a box plot for the DataFrame `df`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a box plot for `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a box plot for `df`\n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b>\n",
    "\n",
    "1) In the 1st code cell below, get a scatter plot for the DataFrame `df`. What happened?\n",
    "2) Try again buy this time declaring `x=` and `y=` parameters for the `.scatter()` method.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a scatter plot for `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a scatter plot for `df`\n",
    "df.plot.scatter(x='Intensity', y='Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame access\n",
    "\n",
    "We can get the information stored in a DataFrame by multiple ways, here we will present the accession by brackets `[]` syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing whole columns\n",
    "\n",
    "In order to access rows, we need to use the brackets syntax: `df[]`. Passing a list of column names inside the brackets grants you access to such columns. Note that there are two pairs of brackets, one enclosing the list of column names (innermost) and one given access to DataFrame columns (outermost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame columns\n",
    "df[['Raw', 'Intensity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing whole rows\n",
    "\n",
    "In order to access rows, we need to use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) followed by the brackets syntax: `df.loc[]`. Passing a list of row indexes inside the brackets grants you access to such rows. Again, note that there are two pairs of brackets, one enclosing the list of row indexes (innermost) and one given access to DataFrame rows (outermost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame rows\n",
    "df.loc[[4, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing columns and rows simultaneously\n",
    "\n",
    "If we want to access the intersection of some columns and rows, we use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) followed by the brackets syntax with a comma inside: `df.loc[ , ]`. The list with the rows we wants goes to the left of the comma and the list with the columns to the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing multiple DataFrame rows and columns simultaneously\n",
    "df.loc[[4, 1],  ['Raw', 'Intensity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, you can first put your lists into a variables before accessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame columns specifying first the list of indices and columns we want\n",
    "rows = [4, 1]\n",
    "cols = ['Raw', 'Intensity']\n",
    "df.loc[rows, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Some Series methods?\n",
    "quantile()\n",
    "sum()\n",
    "min()\n",
    "max()\n",
    "mean()\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame boolean indexing\n",
    "\n",
    "Do you remember the six *comparison operators*? \n",
    "+ `==`: Equal.\n",
    "+ `!=`: Not equal.\n",
    "+ `>`: Greater than.\n",
    "+ `<`: Less than.\n",
    "+ `>=`: Greater than or equal to.\n",
    "+ `<=`: Less than or equal to.\n",
    "\n",
    "We can use them to know which DataFrame rows affirmatively *answer* our *question*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the current index 'Intensity' greater than 100?\n",
    "df['Intensity'] > 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, can use the *logical operators* `and`, `or`, `not`, but in their *bitwise* form `&`, `|`, `~`, respectively to link multiple \"questions\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b>\n",
    "\n",
    "Keep in mind that DataFrame \"questions\" should be enclosed by parenthesis before linking them using `&`, `|`, `~`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the current index 'Intensity' greater than 100 AND 'Amplitude' smaller than 1.6?\n",
    "(df['Intensity'] > 100) & (df['Amplitude'] < 1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the current index 'Software' not equal to 'PD' OR 'Node' equal to 'Amanda'?\n",
    "(df['Software'] != 'PD') | (df['Node'] == 'Amanda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b>\n",
    "\n",
    "1) In the 1st code cell below, ask our DataFrame `df` to get which rows present an `'Intensity'` lower than `90` **or** higher than `140`, **and**, a `'Node'` named `'Andromeda'` **or** `'Amanda'`.\n",
    "2) Inspect the DataFrame `df` and verify that boolean indexation is giving the correct answers.    \n",
    "\n",
    "Un-comment and fill only those code lines with underscores `___`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Is the current index 'Software' not equal to 'PD' OR 'Node' equal to 'Amanda'?\n",
    "#print(( (df['Intensity'] _ ___) _ (df['Intensity'] _ ___) ) & ( (df['Node'] _ '___') _ (df['Node'] _ '___') ))\n",
    "\n",
    "# Return the DataFrame\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# Is the current index 'Software' not equal to 'PD' OR 'Node' equal to 'Amanda'?\n",
    "print(( (df['Intensity'] > 140) | (df['Intensity'] < 90) ) & ( (df['Node'] == 'Andromeda') | (df['Node'] == 'Amanda') ))\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering DataFrames with boolean indexing\n",
    "\n",
    "You can store the output of a boolean indexing into a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filter to get Proteome Discoverer software AND no to get Amanda search node.\n",
    "bool_series = (df['Software'] == 'PD') & (df['Node'] != 'Amanda')\n",
    "\n",
    "# Get the variable type of `bool_series`\n",
    "type(bool_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of a boolean indexation (question) is a Pandas Series, in particular a Series full of boolean values, aka *boolean Series* (answer). We can use such *boolean Series* to easily filter *DataFrames* in a very flexible way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying my (first) filter to my DataFrame\n",
    "df[bool_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b>\n",
    "\n",
    "You can rethink a *boolean Series* as a dataFrame \"mask\" that leaves uncovered only those rows of your interest.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b>\n",
    "\n",
    "In the 1st code cell below, we computed the 60% quantile of the 'Intensity' `I_quantile` and the 40% quantile of the 'Amplitude' `A_quantile`. Use this two variables that we have prepared for you to:\n",
    "    \n",
    "1) In the 2nd code cell below, create a boolean Series called `first_filter` to filter high intensity values (` > I_quantile`) or low amplitude values (` < A_quantile`) from the DataFrame `df`.\n",
    "2) In the 3rd code cell below, use `first_filter` to get your rows of interest from the *DataFrame* `df`.\n",
    "3) What you should change when creating `first_filter` if you would prefer high intensity values *and* low amplitude values (instead of *or*). Create a boolean Series called `second_filter` for this purpose in the 3rd cell below, and get your new rows of interest from the *DataFrame* `df`.\n",
    "    \n",
    "Un-comment and fill only those code lines with underscores `___`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Retrieving the 60% quantile of the 'Intensity': I_quantile\n",
    "I_quantile = df['Intensity'].quantile(0.60)\n",
    "print(I_quantile)\n",
    "\n",
    "# Retrieving the 40% quantile of the 'Amplitude': A_quantile\n",
    "A_quantile = df['Amplitude'].quantile(0.40)\n",
    "print(A_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Create filter to get high peak intensity (first 60% quantile) OR low peak amplitude (last 40% quantile)\n",
    "#first_filter = \n",
    "\n",
    "# Applying first filter to DataFrame\n",
    "#df[___]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2,
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# Create filter to get high peak intensity (first quantile) OR low peak amplitude (last quantile)\n",
    "first_filter = (df['Intensity'] > I_quantile) | (df['Amplitude'] < A_quantile)\n",
    "\n",
    "# Applying first filter to DataFrame\n",
    "df[first_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Create filter to get high peak intensity (first 60% quantile) AND low peak amplitude (last 40% quantile)\n",
    "#second_filter = \n",
    "\n",
    "# Applying second filter to DataFrame\n",
    "#df[___]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# Create filter to get high peak intensity (first quantile) AND low peak amplitude (last quantile)\n",
    "second_filter = (df['Intensity'] > I_quantile) & (df['Amplitude'] < A_quantile)\n",
    "\n",
    "# Applying second filter to DataFrame\n",
    "df[second_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame transformations\n",
    "\n",
    "Pr√°cticamente a diario necesitaremos procesar los datos almacenados en un *DataFrame*. Podr√≠amos necesitar crear una columna a partir de otra, o aplicar una misma transformaci√≥n a m√∫ltiples columnas, o construir una tabla din√°mica..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame numerical transformations\n",
    "\n",
    "A modo de ejemplo, intentaremos calcular el *Z-score* de la intensidad. Recuerda que la $i$-√©sima observaci√≥n de una magnitud $x$, $(x_i)$, tiene un *Z-score*, $(Z_i)$, dado por la siguiente ecuaci√≥n:\n",
    "\n",
    "\\begin{equation}\n",
    "Z_i = \\frac{x_i - \\mu(x)}{\\sigma(x)}\n",
    "\\end{equation}\n",
    "\n",
    "Aqu√≠, $\\mu(x)$ y $\\sigma(x)$ representan la media y la desviaci√≥n est√°ndar de $x$, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Z-score of the 'Intensity' column and storing it in a new 'Z-Intensity' column\n",
    "df['Z-Intensity'] = ( (df['Intensity']) - (df['Intensity'].mean()) ) / ( df['Intensity'].std() )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">üí° **M√°s informaci√≥n:**\n",
    ">\n",
    "> Los m√©todos de **Pandas** [`.std()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html) y [`.mean()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) son muy √∫tiles para hacer agragaciones estad√≠sticas sencillas como la desviaci√≥n est√°ndar y la media. [Aqu√≠](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html#descriptive-statistics) puedes consultar todos los m√©todos disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "source": [
    "> ‚úèÔ∏è **Pr√°ctica:**\n",
    ">\n",
    "> Calcula la normalizaci√≥n de 0 a 1 para la amplitud. Recuerda que la $i$-√©sima observaci√≥n de una magnitud $x$, $(x_i)$, tiene una normalizaci√≥n de 0 a 1, $(N_i)$, dada por la siguiente ecuaci√≥n:\n",
    "> \n",
    ">\\begin{equation}\n",
    "N_i = \\frac{x_i - m(x)}{M(x) - m(x)}\n",
    "\\end{equation}\n",
    "> \n",
    "> Aqu√≠, $m(x)$ y $M(x)$ representan los valores m√≠nimo y m√°ximo de $x$, respectivamente.\n",
    "> \n",
    "> **Pista**: Los *DataFrames* de **Pandas** tienen dos m√©todos que te vendr√°n muy bien: [`.min()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.min.html) y [`.max()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.max.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio",
     "error"
    ]
   },
   "outputs": [],
   "source": [
    "# Computing the N-normalization of the 'Amplitude' column and storing it in a new 'N-Amplitude' column\n",
    "#df['N-Amplitude'] = ___\n",
    "\n",
    "# Return the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Computing the N-normalization of the 'Amplitude' column and storing it in a new 'N-Amplitude' column\n",
    "df['N-Amplitude'] = (df['Amplitude'] - df['Amplitude'].min()) / (df['Amplitude'].max() - df['Amplitude'].min())\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos el *Z-score* de la intensidad y la normalizaci√≥n de 0 a 1 de la amplitud en dos columnas independientes, podr√≠amos descartar las columnas originales de intensidad y amplitud con el m√©todo [`.drop()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html).\n",
    "\n",
    ">üí° **M√°s informaci√≥n:**\n",
    ">\n",
    "> El par√°metro `axis=` del m√©todo `.drop` especifica si la lista de etiquetas que queremos descartar hace referencia a los √≠ndices (`axis=0`) o a las columnas (`axis=1`). Alternativamente, se pueden utilizar los par√°metros `index=` y `columns=`, los cuales resultan mucho m√°s intuitivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns 'Intensity' and 'Amplitude'\n",
    "df = df.drop(['Intensity', 'Amplitude'], axis=1)\n",
    "#df = df.drop(columns=['Intensity', 'Amplitude'])\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como norma general es buena pr√°ctica usar nombres cortos para las columnas de un *DataFrame*. El m√©todo [`.rename()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) permite renombrar las columnas de un *DataFrame* mediante un diccionario. Las *keys* de este diccionario ser√°n los nombres originales y los *values* ser√°n los nombres nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a renaming dictionary for incomming column rename\n",
    "rename_dic = {'Software': 'Soft',\n",
    "              'Sequence': 'Seq',\n",
    "              'Z-Intensity': 'I',\n",
    "              'N-Amplitude': 'A'}\n",
    "\n",
    "# Applying my (first) column rename to my DataFrame\n",
    "df = df.rename(rename_dic, axis=1)\n",
    "#df = df.rename(columns=rename_dic)\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame text transformations\n",
    "\n",
    "Adem√°s de transformaciones num√©ricas podemos operar con cadenas de car√°cteres (*strings*). Esto resulta particularmente √∫til para trabajar con secuencias de amino√°cidos. Por ejemplo, vemos que los *strings* de la columna `df['Raw']` tienen una estructura bien organizada, ya que constan de varios *substrings* separados por barras bajas `_`. Podemos encontrar un *substring* independiente para la fecha (`1985-04-06`), otro *substring* para el n√∫mero de seguimento del trabajo (`0123`), otro para las iniciales del usuario (`GA`), otro para la condici√≥n experimental (`T` / `C`) y otro para la r√©plica (`R1` / `R2` / `R3` / `R4`). A veces puede resultar muy √∫til incorporar esta informaci√≥n en nuestro *DataFrame*.\n",
    "\n",
    "Las columnas (o *Series*) de un *DataFrame* poseen el m√©todo [`.str`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.html). Este m√©todo da acceso a los *strings* almacenados en la *Series*. Una vez tenemos la *Series* bajo el efecto del m√©todo `.str` podemos utilizar cualquiera de los m√©todos disponibles para un *string*,  como por ejemplo `.split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the 'Raw' column by the underscore '_'\n",
    "df['Split raw'] = df['Raw'].str.split('_')\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the 4th element of the list in 'Split raw' as 'Cond'\n",
    "df['Cond'] = df['Split raw'].str[3]\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "source": [
    "> ‚úèÔ∏è **Pr√°ctica:**\n",
    ">\n",
    "> Crea una columna llamada `df['Repl']` para los replicados `R1`, `R2`, `R3` y `R4` tal y como aparecen en la columna `df['Raw']`. Luego descarta las columnas redundantes `df['Raw']` y `df['Split raw']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Taking the 5th element of the list in 'Split raw' as 'Repl'\n",
    "#df['Repl'] = ___\n",
    "\n",
    "\n",
    "# Dropping redundant columns 'Raw' and 'Split raw'\n",
    "#df = df.drop(___)\n",
    "\n",
    "\n",
    "# Return the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Taking the 5th element of the list in 'Split raw' as 'Repl'\n",
    "df['Repl'] = df['Split raw'].str[4]\n",
    "\n",
    "# Dropping redundant columns 'Raw' and 'Split raw'\n",
    "df = df.drop(['Raw', 'Split raw'], axis=1)\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acabar con este cap√≠tulo, simplemente exportaremos nuestro *DataFrame* en forma de archivo **Excel**. Para ello s√≥lo necesitaremos el m√©todo de *DataFrame* [`.to_excel()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html) de **Pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the DataFrame as an Excel SpreadSheet\n",
    "df.to_excel('data/qualitative/Excel_df.xlsx', sheet_name='Excel_df')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "04_Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
